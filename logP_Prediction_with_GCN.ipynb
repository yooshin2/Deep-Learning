{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logP_Prediction_with_GCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea3bae978cdf4b5eb334a22ada86398d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f5435f3277744afeae474864fd88a69a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ba9bfbd05ee495d931c17aa4ec4b307",
              "IPY_MODEL_ea85e8fd05de4899b85c506c10a972fe"
            ]
          }
        },
        "f5435f3277744afeae474864fd88a69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ba9bfbd05ee495d931c17aa4ec4b307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee7cfb609b2844f48939d8daedc0d2d3",
            "_dom_classes": [],
            "description": "Reading Data: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0159bf93649454a854abae750dcea56"
          }
        },
        "ea85e8fd05de4899b85c506c10a972fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_235c4cfed0914106b735c0c7287b88eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [20:02&lt;00:00,  8.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f825e3a43b0e49daa76edbccad9b0b1d"
          }
        },
        "ee7cfb609b2844f48939d8daedc0d2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0159bf93649454a854abae750dcea56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "235c4cfed0914106b735c0c7287b88eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f825e3a43b0e49daa76edbccad9b0b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84d9b482d0eb4f529babd11953f7b62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5defc8725d0540a099f52f4d9f0e27f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97a635f68a6246fbbc5e081512508dba",
              "IPY_MODEL_ed9ffedd33544d628354d2979b59de22"
            ]
          }
        },
        "5defc8725d0540a099f52f4d9f0e27f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97a635f68a6246fbbc5e081512508dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_469b246466724b4faffa91c18f9e1000",
            "_dom_classes": [],
            "description": "Converting to Graph: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47314e06927b4ed1972da97490d08f15"
          }
        },
        "ed9ffedd33544d628354d2979b59de22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71e38f1efe8a4426b7dfb67f6115e952",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10000/10000 [19:59&lt;00:00,  8.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79f367b764614ca0a3a8b11fcad2c49b"
          }
        },
        "469b246466724b4faffa91c18f9e1000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47314e06927b4ed1972da97490d08f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71e38f1efe8a4426b7dfb67f6115e952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79f367b764614ca0a3a8b11fcad2c49b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yooshin2/Deep-Learning/blob/main/logP_Prediction_with_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqUZu4GF2Vtx"
      },
      "source": [
        "# Lab 11. logP value prediction from molecular graph with GCN\n",
        "\n",
        "이번 실습에서는 molecular graph로부터 분자의 특성 중 하나인 logP value를 GCN을 통해 예측해보겠습니다. 이번 실습은 다음과 같은 내용을 포함합니다.\n",
        "\n",
        "- Custom pytorch dataset을 정의하여 여러 input 또는 여러 output이 존재하는 경우를 다뤄보기\n",
        "- Graph convolution을 pytorch로 구현하기\n",
        "- (Gated) skip connection을 pytorch로 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H1XIz2uy8p-"
      },
      "source": [
        "# 0. Install Rdkit\n",
        "\n",
        "분자를 molecular graph 형태로 만들어 주고, 분자의 logP 값을 알려주는 rdkit을 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcQjdidqbx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75499432-d52b-4b1b-cb43-11298b0e2354"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        "\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        "\n",
        "\n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        "\n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        "\n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        "\n",
        "        logger.info(\"force re-install\")\n",
        "\n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        "\n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        "\n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        "\n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python=={}\".format(python_version),\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        "\n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        "\n",
        "install()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "python version: 3.6.9\n",
            "python version: 3.6.9\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "done\n",
            "installing miniconda to /root/miniconda\n",
            "installing miniconda to /root/miniconda\n",
            "done\n",
            "done\n",
            "installing rdkit\n",
            "installing rdkit\n",
            "done\n",
            "done\n",
            "rdkit-2020.09.1 installation finished!\n",
            "rdkit-2020.09.1 installation finished!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnVsqCWhzI6p"
      },
      "source": [
        "분자를 텍스트 형태로 표현한 smiles 파일과 molecular graph를 생성하는데 필요한 vocab.npy 파일을 받습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSl5iLzVsojW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e645177c-6cf2-442a-f047-17e59847f612"
      },
      "source": [
        "!curl -o ZINC.smiles https://raw.githubusercontent.com/heartcored98/Standalone-DeepLearning/master/Lec9/ZINC.smiles\n",
        "!curl -o vocab.npy https://raw.githubusercontent.com/heartcored98/Standalone-DeepLearning/master/Lec9/vocab.npy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5374k  100 5374k    0     0  5168k      0  0:00:01  0:00:01 --:--:-- 5173k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   256  100   256    0     0    764      0 --:--:-- --:--:-- --:--:--   764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1ppocNdreOK"
      },
      "source": [
        "import argparse\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem.Crippen import MolLogP\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tqdm import tnrange, tqdm_notebook\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9bNyAGxsZsr"
      },
      "source": [
        "paser = argparse.ArgumentParser()\n",
        "args = paser.parse_args(\"\")\n",
        "args.seed = 123\n",
        "args.val_size = 0.1\n",
        "args.test_size = 0.1\n",
        "args.shuffle = True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-aKROUUsflT"
      },
      "source": [
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "else:\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkQoOzeLzZA2"
      },
      "source": [
        "# 1. Pre-Processing\n",
        "\n",
        "ZINC.smiles 파일에 text로 표현되어 있는 분자들을 molecular graph 형태로 바꿔줍시다. 이때 node feature matrix는 아래 그림과 같이 각 원자의 symbol, degree 등 화학적 특성을 one-hot vector로 나타낸 형태입니다.\n",
        "![node feature matrix](https://github.com/SeungsuKim/CH485--AI-and-Chemistry/raw/c85ce8716ac2e351d730543a2d45fd7054014d4f/Assignments/5.%20GCN/Graph_Generating_Process.png)\n",
        "\n",
        "`read_ZINC_smiles` 함수는 smiles 파일 내의 분자 텍스트의 list와 각 분자들의 실제 logP value list를 return합니다.\n",
        "`convert_to_graph` 함수는 분자 텍스트의 list를 받아 각 분자들의 `node feature matrix list`와 `adjacency matrix list`를 return 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmABUyC4sg_C"
      },
      "source": [
        "def read_ZINC_smiles(file_name, num_mol):\n",
        "    f = open(file_name, 'r')\n",
        "    contents = f.readlines()\n",
        "\n",
        "    smi_list = []\n",
        "    logP_list = []\n",
        "\n",
        "    for i in tqdm_notebook(range(num_mol), desc='Reading Data'):\n",
        "        smi = contents[i].strip()\n",
        "        m = Chem.MolFromSmiles(smi)\n",
        "        smi_list.append(smi)\n",
        "        logP_list.append(MolLogP(m))\n",
        "\n",
        "    logP_list = np.asarray(logP_list).astype(float)\n",
        "\n",
        "    return smi_list, logP_list\n",
        "\n",
        "\n",
        "def smiles_to_onehot(smi_list):\n",
        "    def smiles_to_vector(smiles, vocab, max_length):\n",
        "        while len(smiles) < max_length:\n",
        "            smiles += \" \"\n",
        "        vector = [vocab.index(str(x)) for x in smiles]\n",
        "        one_hot = np.zeros((len(vocab), max_length), dtype=int)\n",
        "        for i, elm in enumerate(vector):\n",
        "            one_hot[elm][i] = 1\n",
        "        return one_hot\n",
        "\n",
        "    vocab = np.load('./vocab.npy')\n",
        "    smi_total = []\n",
        "\n",
        "    for i, smi in tqdm_notebook(enumerate(smi_list), desc='Converting to One Hot'):\n",
        "        smi_onehot = smiles_to_vector(smi, list(vocab), 120)\n",
        "        smi_total.append(smi_onehot)\n",
        "\n",
        "    return np.asarray(smi_total)\n",
        "\n",
        "def convert_to_graph(smiles_list):\n",
        "    adj = []\n",
        "    adj_norm = []\n",
        "    features = []\n",
        "    maxNumAtoms = 50\n",
        "    for i in tqdm_notebook(smiles_list, desc='Converting to Graph'):\n",
        "        # Mol\n",
        "        iMol = Chem.MolFromSmiles(i.strip())\n",
        "        #Adj\n",
        "        iAdjTmp = Chem.rdmolops.GetAdjacencyMatrix(iMol)\n",
        "        # Feature\n",
        "        if( iAdjTmp.shape[0] <= maxNumAtoms):\n",
        "            # Feature-preprocessing\n",
        "            iFeature = np.zeros((maxNumAtoms, 58))\n",
        "            iFeatureTmp = []\n",
        "            for atom in iMol.GetAtoms():\n",
        "                iFeatureTmp.append( atom_feature(atom) ) ### atom features only\n",
        "            iFeature[0:len(iFeatureTmp), 0:58] = iFeatureTmp ### 0 padding for feature-set\n",
        "            features.append(iFeature)\n",
        "\n",
        "            # Adj-preprocessing\n",
        "            iAdj = np.zeros((maxNumAtoms, maxNumAtoms))\n",
        "            iAdj[0:len(iFeatureTmp), 0:len(iFeatureTmp)] = iAdjTmp + np.eye(len(iFeatureTmp))\n",
        "            adj.append(np.asarray(iAdj))\n",
        "    features = np.asarray(features)\n",
        "\n",
        "    return features, adj\n",
        "    \n",
        "def atom_feature(atom):\n",
        "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
        "                                      ['C', 'N', 'O', 'S', 'F', 'H', 'Si', 'P', 'Cl', 'Br',\n",
        "                                       'Li', 'Na', 'K', 'Mg', 'Ca', 'Fe', 'As', 'Al', 'I', 'B',\n",
        "                                       'V', 'Tl', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
        "                                       'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'Mn', 'Cr', 'Pt', 'Hg', 'Pb']) +\n",
        "                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
        "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
        "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
        "                    [atom.GetIsAromatic()])    # (40, 6, 5, 6, 1)\n",
        "\n",
        "def one_of_k_encoding(x, allowable_set):\n",
        "    if x not in allowable_set:\n",
        "        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n",
        "    return list(map(lambda s: x == s, allowable_set))\n",
        "\n",
        "def one_of_k_encoding_unk(x, allowable_set):\n",
        "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
        "    if x not in allowable_set:\n",
        "        x = allowable_set[-1]\n",
        "    return list(map(lambda s: x == s, allowable_set))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVS1hxmcsiwO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204,
          "referenced_widgets": [
            "ea3bae978cdf4b5eb334a22ada86398d",
            "f5435f3277744afeae474864fd88a69a",
            "0ba9bfbd05ee495d931c17aa4ec4b307",
            "ea85e8fd05de4899b85c506c10a972fe",
            "ee7cfb609b2844f48939d8daedc0d2d3",
            "a0159bf93649454a854abae750dcea56",
            "235c4cfed0914106b735c0c7287b88eb",
            "f825e3a43b0e49daa76edbccad9b0b1d",
            "84d9b482d0eb4f529babd11953f7b62a",
            "5defc8725d0540a099f52f4d9f0e27f2",
            "97a635f68a6246fbbc5e081512508dba",
            "ed9ffedd33544d628354d2979b59de22",
            "469b246466724b4faffa91c18f9e1000",
            "47314e06927b4ed1972da97490d08f15",
            "71e38f1efe8a4426b7dfb67f6115e952",
            "79f367b764614ca0a3a8b11fcad2c49b"
          ]
        },
        "outputId": "998848cf-2432-4f45-eebd-6e48149f3061"
      },
      "source": [
        "list_smi, list_logP = read_ZINC_smiles('ZINC.smiles', 10000)\n",
        "list_feature, list_adj = convert_to_graph(list_smi)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3bae978cdf4b5eb334a22ada86398d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Reading Data', max=10000.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d9b482d0eb4f529babd11953f7b62a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Converting to Graph', max=10000.0, style=ProgressStyle(de…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aT67R-21Yb0"
      },
      "source": [
        "위 코드를 통해 원하는 수 만큼의 분자들의 node feature matrix list인 `list_feature`, adjacency matrix list인 `list_adj`, 그리고 logP value list인 `list_logP`를 얻었습니다.\n",
        "\n",
        "그 동안의 실습에서는 이미지로부터 이미지의 label을 얻는, 즉 하나의 input에서 하나의 output을 얻는 형태였지만, 이번 실습에서는 두 개의 input, `list_feature`와 `list_adj`로부터 logP value라는 하나의 output을 얻어내야합니다. 이를 위해 custom pytorch dataset을 정의하고 사용해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cup8LdcyslSw"
      },
      "source": [
        "class GCNDataset(Dataset):\n",
        "    def __init__(self, list_feature, list_adj, list_logP):\n",
        "        self.list_feature = list_feature\n",
        "        self.list_adj = list_adj\n",
        "        self.list_logP = list_logP\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_feature)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.list_feature[index], self.list_adj[index], self.list_logP[index]\n",
        "\n",
        "\n",
        "def partition(list_feature, list_adj, list_logP, args):\n",
        "    num_total = list_feature.shape[0]\n",
        "    num_train = int(num_total * (1 - args.test_size - args.val_size))\n",
        "    num_val = int(num_total * args.val_size)\n",
        "    num_test = int(num_total * args.test_size)\n",
        "\n",
        "    feature_train = list_feature[:num_train]\n",
        "    adj_train = list_adj[:num_train]\n",
        "    logP_train = list_logP[:num_train]\n",
        "    feature_val = list_feature[num_train:num_train + num_val]\n",
        "    adj_val = list_adj[num_train:num_train + num_val]\n",
        "    logP_val = list_logP[num_train:num_train + num_val]\n",
        "    feature_test = list_feature[num_total - num_test:]\n",
        "    adj_test = list_adj[num_total - num_test:]\n",
        "    logP_test = list_logP[num_total - num_test:]\n",
        "        \n",
        "    train_set = GCNDataset(feature_train, adj_train, logP_train)\n",
        "    val_set = GCNDataset(feature_val, adj_val, logP_val)\n",
        "    test_set = GCNDataset(feature_test, adj_test, logP_test)\n",
        "\n",
        "    partition = {\n",
        "        'train': train_set,\n",
        "        'val': val_set,\n",
        "        'test': test_set\n",
        "    }\n",
        "\n",
        "    return partition"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARzvpF8VvM1z"
      },
      "source": [
        "partition = partition(list_feature, list_adj, list_logP, args)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syXomETq2RkZ"
      },
      "source": [
        "# 2. Model Construction\n",
        "\n",
        "Graph Convolution Network, 즉 GCN을 pytorch를 이용하여 구현하여봅시다. 이를 위해 다음과 같은 sub module들을 구현하고 사용합니다.\n",
        "\n",
        "- **GCNLayer**: node feature matrix와 adjacency matrix의 list를 받아 graph convolution 연산을 수행하는 module 입니다.\n",
        "- **(Gated)SkipConnection**: ResNet에서 사용되었던 skip connection technique을 구현한 module 입니다.\n",
        "- **GCNBlock**: node feature matrix와 adjacency matrix의 list를 받아 원하는 갯수의 GCNLayer를 통과시킨 후, (gated)skip connection을 적용하는 module 입니다.\n",
        "- **ReadOut**: graph structrure에 permutation invariance를 주기 위하여 linear layer를 거친 뒤 batch 별로 summation하는 module 입니다.\n",
        "- **Predictor**: ReadOut layer로부터의 graph feature vector로부터 logP value를 예측하기 위한 linear layer module 입니다.\n",
        "\n",
        "위 모듈들을 사용하여 **GCNNet**을 구현해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mws4qjmEpGda"
      },
      "source": [
        "class Attention(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, in_dim, output_dim, num_head):\r\n",
        "        super(Attention, self).__init__()\r\n",
        "        \r\n",
        "        self.num_head = num_head\r\n",
        "        self.atn_dim = output_dim // num_head\r\n",
        "        \r\n",
        "        self.linears = nn.ModuleList()\r\n",
        "        self.corelations = nn.ParameterList()\r\n",
        "        for i in range(self.num_head):\r\n",
        "            self.linears.append(nn.Linear(in_dim, self.atn_dim))\r\n",
        "            corelation = torch.FloatTensor(self.atn_dim, self.atn_dim)\r\n",
        "            nn.init.xavier_uniform_(corelation)\r\n",
        "            self.corelations.append(nn.Parameter(corelation))\r\n",
        "            \r\n",
        "        self.tanh = nn.Tanh()\r\n",
        "        \r\n",
        "    def forward(self, x, adj):\r\n",
        "        heads = list()\r\n",
        "        for i in range(self.num_head):\r\n",
        "            x_transformed = self.linears[i](x)\r\n",
        "            alpha = self.attention_matrix(x_transformed, self.corelations[i], adj)\r\n",
        "            x_head = torch.matmul(alpha, x_transformed)\r\n",
        "            heads.append(x_head)\r\n",
        "        output = torch.cat(heads, dim=2)\r\n",
        "        return output\r\n",
        "            \r\n",
        "    def attention_matrix(self, x_transformed, corelation, adj):\r\n",
        "        x = torch.einsum('akj,ij->aki', (x_transformed, corelation))\r\n",
        "        alpha = torch.matmul(x, torch.transpose(x_transformed, 1, 2))\r\n",
        "        alpha = torch.mul(alpha, adj)\r\n",
        "        alpha = self.tanh(alpha)\r\n",
        "        return alpha"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf7u-LKN2Mhx"
      },
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim, n_atom, act=None, bn=False, atn=False, num_head=1):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        \n",
        "        self.use_bn = bn\n",
        "        self.linear = nn.Linear(in_dim, out_dim)\n",
        "        nn.init.xavier_uniform_(self.linear.weight)\n",
        "        self.bn = nn.BatchNorm1d(n_atom)\n",
        "        self.activation = act\n",
        "        self.use_atn = atn\n",
        "        self.num_head = num_head\n",
        "        self.attention = Attention(out_dim, out_dim, num_head)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        out = self.linear(x)\n",
        "        if self.atn:\n",
        "            out = self.attention(out, adj)\n",
        "        else:\n",
        "            out = torch.matmul(adj, out)\n",
        "        if self.use_bn:\n",
        "            out = self.bn(out)\n",
        "        if self.activation != None:\n",
        "            out = self.activation(out)\n",
        "        return out, adj"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be35zGHo5GrG"
      },
      "source": [
        "class SkipConnection(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(SkipConnection, self).__init__()\n",
        "        \n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "        self.linear = nn.Linear(in_dim, out_dim, bias=False)\n",
        "        \n",
        "    def forward(self, in_x, out_x):\n",
        "        if (self.in_dim != self.out_dim):\n",
        "            in_x = self.linear(in_x)\n",
        "        out = in_x + out_x\n",
        "        return out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbnG438p5J_9"
      },
      "source": [
        "class GatedSkipConnection(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(GatedSkipConnection, self).__init__()\n",
        "        \n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "        self.linear = nn.Linear(in_dim, out_dim, bias=False)\n",
        "        self.linear_coef_in = nn.Linear(out_dim, out_dim)\n",
        "        self.linear_coef_out = nn.Linear(out_dim, out_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, in_x, out_x):\n",
        "        if (self.in_dim != self.out_dim):\n",
        "            in_x = self.linear(in_x)\n",
        "        z = self.gate_coefficient(in_x, out_x)\n",
        "        out = torch.mul(z, out_x) + torch.mul(1.0-z, in_x)\n",
        "        return out\n",
        "            \n",
        "    def gate_coefficient(self, in_x, out_x):\n",
        "        x1 = self.linear_coef_in(in_x)\n",
        "        x2 = self.linear_coef_out(out_x)\n",
        "        return self.sigmoid(x1+x2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSj6nv1x5L_A"
      },
      "source": [
        "class GCNBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_layer, in_dim, hidden_dim, out_dim, n_atom, bn=True, sc='gsc'):\n",
        "        super(GCNBlock, self).__init__()\n",
        "        \n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(n_layer):\n",
        "            self.layers.append(GCNLayer(in_dim if i==0 else hidden_dim,\n",
        "                                        out_dim if i==n_layer-1 else hidden_dim,\n",
        "                                        n_atom,\n",
        "                                        nn.ReLU() if i!=n_layer-1 else None,\n",
        "                                        bn))\n",
        "        self.relu = nn.ReLU()\n",
        "        if sc=='gsc':\n",
        "            self.sc = GatedSkipConnection(in_dim, out_dim)\n",
        "        elif sc=='sc':\n",
        "            self.sc = SkipConnection(in_dim, out_dim)\n",
        "        elif sc=='no':\n",
        "            self.sc = None\n",
        "        else:\n",
        "            assert False, \"Wrong sc type.\"\n",
        "        \n",
        "    def forward(self, x, adj):\n",
        "        residual = x\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            out, adj = layer((x if i==0 else out), adj)\n",
        "        if self.sc != None:\n",
        "            out = self.sc(residual, out)\n",
        "        out = self.relu(out)\n",
        "        return out, adj"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIzrq22j5cnC"
      },
      "source": [
        "class ReadOut(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim, act=None):\n",
        "        super(ReadOut, self).__init__()\n",
        "        \n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim= out_dim\n",
        "        \n",
        "        self.linear = nn.Linear(self.in_dim, \n",
        "                                self.out_dim)\n",
        "        nn.init.xavier_uniform_(self.linear.weight)\n",
        "        self.activation = act\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        out = torch.sum(out, 1)\n",
        "        if self.activation != None:\n",
        "            out = self.activation(out)\n",
        "        return out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdrraB1U5dJI"
      },
      "source": [
        "class Predictor(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_dim, out_dim, act=None):\n",
        "        super(Predictor, self).__init__()\n",
        "        \n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        \n",
        "        self.linear = nn.Linear(self.in_dim,\n",
        "                                self.out_dim)\n",
        "        nn.init.xavier_uniform_(self.linear.weight)\n",
        "        self.activation = act\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        if self.activation != None:\n",
        "            out = self.activation(out)\n",
        "        return out"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbrHcW8u5e9_"
      },
      "source": [
        "class GCNNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, args):\n",
        "        super(GCNNet, self).__init__()\n",
        "        \n",
        "        self.blocks = nn.ModuleList()\n",
        "        for i in range(args.n_block):\n",
        "            self.blocks.append(GCNBlock(args.n_layer,\n",
        "                                        args.in_dim if i==0 else args.hidden_dim,\n",
        "                                        args.hidden_dim,\n",
        "                                        args.hidden_dim,\n",
        "                                        args.n_atom,\n",
        "                                        args.bn,\n",
        "                                        args.sc))\n",
        "        self.readout = ReadOut(args.hidden_dim, \n",
        "                               args.pred_dim1,\n",
        "                               act=nn.ReLU())\n",
        "        self.pred1 = Predictor(args.pred_dim1,\n",
        "                               args.pred_dim2,\n",
        "                               act=nn.ReLU())\n",
        "        self.pred2 = Predictor(args.pred_dim2,\n",
        "                               args.pred_dim3,\n",
        "                               act=nn.Tanh())\n",
        "        self.pred3 = Predictor(args.pred_dim3,\n",
        "                               args.out_dim)\n",
        "        \n",
        "    def forward(self, x, adj):\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            out, adj = block((x if i==0 else out), adj)\n",
        "        out = self.readout(out)\n",
        "        out = self.pred1(out)\n",
        "        out = self.pred2(out)\n",
        "        out = self.pred3(out)\n",
        "        return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAuK_Om_D9PB"
      },
      "source": [
        "# 3. Train, Validate, Test and Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yCpvH4G6IdN"
      },
      "source": [
        "def train(net, partition, optimizer, criterion, args):\n",
        "    trainloader = torch.utils.data.DataLoader(partition['train'], \n",
        "                                              batch_size=args.train_batch_size, \n",
        "                                              shuffle=True, num_workers=2)\n",
        "    net.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        optimizer.zero_grad() # [21.01.05 오류 수정] 매 Epoch 마다 .zero_grad()가 실행되는 것을 매 iteration 마다 실행되도록 수정했습니다. \n",
        "\n",
        "        # get the inputs\n",
        "        list_feature, list_adj, list_logP = data\n",
        "        list_feature = list_feature.cuda().float()\n",
        "        list_adj = list_adj.cuda().float()\n",
        "        list_logP = list_logP.cuda().float().view(-1, 1)\n",
        "        outputs = net(list_feature, list_adj)\n",
        "\n",
        "        loss = criterion(outputs, list_logP)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss = train_loss / len(trainloader)\n",
        "    return net, train_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVcwCjqWrs2I"
      },
      "source": [
        "def validate(net, partition, criterion, args):\n",
        "    valloader = torch.utils.data.DataLoader(partition['val'], \n",
        "                                            batch_size=args.test_batch_size, \n",
        "                                            shuffle=False, num_workers=2)\n",
        "    net.eval()\n",
        "    val_loss = 0 \n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            list_feature, list_adj, list_logP = data\n",
        "            list_feature = list_feature.cuda().float()\n",
        "            list_adj = list_adj.cuda().float()\n",
        "            list_logP = list_logP.cuda().float().view(-1, 1)\n",
        "            \n",
        "            outputs = net(list_feature, list_adj)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        val_loss = val_loss / len(valloader)\n",
        "    return val_loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVBEx-gtrtcr"
      },
      "source": [
        "def test(net, partition, args):\n",
        "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
        "                                             batch_size=args.test_batch_size, \n",
        "                                             shuffle=False, num_workers=2)\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        logP_total = list()\n",
        "        pred_logP_total = list()\n",
        "        for data in testloader:\n",
        "            list_feature, list_adj, list_logP = data\n",
        "            list_feature = list_feature.cuda().float()\n",
        "            list_adj = list_adj.cuda().float()\n",
        "            list_logP = list_logP.cuda().float()\n",
        "            logP_total += list_logP.tolist()\n",
        "            list_logP = list_logP.view(-1, 1)\n",
        "            \n",
        "            outputs = net(list_feature, list_adj)\n",
        "            pred_logP_total += outputs.view(-1).tolist()\n",
        "\n",
        "        mae = mean_absolute_error(logP_total, pred_logP_total)\n",
        "        std = np.std(np.array(logP_total)-np.array(pred_logP_total))\n",
        "    \n",
        "    return mae, std, logP_total, pred_logP_total"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arv4TE2vrtey"
      },
      "source": [
        "def experiment(partition, args):\n",
        "  \n",
        "    net = GCNNet()\n",
        "    net.cuda()\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    if args.optim == 'SGD':\n",
        "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    elif args.optim == 'Adam':\n",
        "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
        "    else:\n",
        "        raise ValueError('In-valid optimizer choice')\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "        \n",
        "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
        "        ts = time.time()\n",
        "        net, train_loss = train(net, partition, optimizer, criterion, args)\n",
        "        val_loss = validate(net, partition, criterion, args)\n",
        "        te = time.time()\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        \n",
        "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
        "        \n",
        "    mae, std, logP_total, pred_logP_total = test(net, partition, args)    \n",
        "    \n",
        "    result = {}\n",
        "    result['train_losses'] = train_losses\n",
        "    result['val_losses'] = val_losses\n",
        "    result['mae'] = mae\n",
        "    result['std'] = std\n",
        "    result['logP_total'] = logP_total\n",
        "    result['pred_logP_total'] = pred_logP_total\n",
        "    return vars(args), result"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c7OVIAVu0Ta"
      },
      "source": [
        "# 4. Manage Experiment Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmlvi6pVu3V8"
      },
      "source": [
        "import hashlib\r\n",
        "import json\r\n",
        "from os import listdir\r\n",
        "from os.path import isfile, join\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "def save_exp_result(setting, result):\r\n",
        "    exp_name = setting['exp_name']\r\n",
        "    del setting['epoch']\r\n",
        "    del setting['test_batch_size']\r\n",
        "\r\n",
        "    hash_key = hashlib.sha1(str(setting).encode()).hexdigest()[:6]\r\n",
        "    filename = './results/{}-{}.json'.format(exp_name, hash_key)\r\n",
        "    result.update(setting)\r\n",
        "    with open(filename, 'w') as f:\r\n",
        "        json.dump(result, f)\r\n",
        "\r\n",
        "    \r\n",
        "def load_exp_result(exp_name):\r\n",
        "    dir_path = './results'\r\n",
        "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if '.json' in f]\r\n",
        "    list_result = []\r\n",
        "    for filename in filenames:\r\n",
        "        if exp_name in filename:\r\n",
        "            with open(join(dir_path, filename), 'r') as infile:\r\n",
        "                results = json.load(infile)\r\n",
        "                list_result.append(results)\r\n",
        "    df = pd.DataFrame(list_result) # .drop(columns=[])\r\n",
        "    return df"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1uDmKj0lTAq"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0bJilMNlXzC"
      },
      "source": [
        "def plot_distribution(df_result, var1, var2):\r\n",
        "    def scatter(x, y, **kwargs):\r\n",
        "        plt.scatter(x[0], y[0], alpha=0.3, s=2)\r\n",
        "    def identity(x, **kwargs):\r\n",
        "        plt.plot(x[0], x[0], alpha=0.4, color='black')\r\n",
        "    \r\n",
        "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\r\n",
        "    g = sns.FacetGrid(df_result, row=var1, col=var2, margin_titles=True)\r\n",
        "    g.map(scatter, 'logP_total', 'pred_logP_total')\r\n",
        "    g.map(identity, 'logP_total', 'logP_total')\r\n",
        "    g.fig.suptitle('Truth Distribution depends on ' + var1 + ' vs ' + var2, size=16)\r\n",
        "    g.fig.subplots_adjust(top=.9)\r\n",
        "    plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}